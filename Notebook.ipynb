{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GDG school](Images/Artboard_2.png)\n",
    "\n",
    "# **GDG school ML workshop**\n",
    "### Table of content \n",
    "\n",
    "\n",
    "1.   **Machine learning :**\n",
    "\n",
    "\n",
    "*   What's Machine learning ?\n",
    "\n",
    "*   The difference between ML and traditional programming.\n",
    "*   AI, ML and Deep learning.\n",
    "2.  **Machine learning pipeline**\n",
    "*  Collect data\n",
    "*  Preparing data\n",
    "* Choosing model \n",
    "* Training\n",
    "* Evaluation \n",
    "3.  **Solving problems using AI**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.   **Machine learning :** \n",
    "*   **What's Machine learning ?**\n",
    "\n",
    "\n",
    "### Some examples of machine learning \n",
    "#   **Is that ML ?** \n",
    "### autonomus cars\n",
    "![autonomus cars](Images/giphy.gif) \n",
    "Autonomous cars apply a wide range of techniques to function. These include statistics, robotics, and machine learning.\n",
    "\n",
    "### online ad optimization ?\n",
    "In order to optimize ads online, machine learning and statistics are needed to deliver the correct type of ads to the right audience, and to measure the effectiveness of the optimization.\n",
    "\n",
    "### Customer service chatbot\n",
    "![](Images/PastelFriendlyGibbon-size_restricted.gif)\n",
    "A customer service chatbot will need machine learning to process human produced language in such a way that it can act on it.\n",
    "\n",
    "\n",
    "* #   **The difference between ML and traditional programming.**\n",
    "\n",
    "![Traditionnal programming](Images/2020-01-09_232844.png)\n",
    "\n",
    "We express rules in a programming language. These act on data and our program provides answers. We write rules in any programming language and those will act on data we get answers\n",
    "\n",
    "![Machine learning](Images/2020-01-09_232855.png)\n",
    "What if we could provide a lot of labeled answers and it inferences rules? the model will try to determine, from the data, what the distinct patterns that denote a particular case are.\n",
    "### When this happens ?\n",
    "So our model will have a bunch of data in the training phase and now using rules infered from the training phase he'll capable to make \"*predictions*\"\n",
    "![training phase](Images/2020-01-09_232915.png)\n",
    "\n",
    "\n",
    "### Generalization \n",
    "> The goal of ML is never to make ‚Äúperfect‚Äù guesses, because ML deals in domains where there is no such thing. The goal is to make guesses that are good enough to be useful.\n",
    "\n",
    "![meme](Images/75481841_2450909828504762_89711125100232704_n.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  **AI, ML and Deep learning.**\n",
    "\n",
    "Simply said: Artificial intelligence (AI) is the ability of a computer program or a machine to think like humans do.\n",
    "AI is using technology to do things which used to require human intelligence, for example problem solving or learning, and will likely shape our future more than any technology that has come before.\n",
    "Machine learning (ML) is a subfield of AI and gives machines the skills to ‚Äòlearn‚Äô from examples without being explicitly programmed to do so. Deep learning (DL) is a specialized ML technique that mimics the behavior of the human brain and enables machines to train themselves to perform tasks.\n",
    "![AI,ML and DL](Images/Intro_to_ML.png)\n",
    "\n",
    "\n",
    "Source ( [schoolofdisruption](https://schoolofdisruption.com/exponential-technologies/artificial-intelligence/))\n",
    "\n",
    "\n",
    "# 2.  **Machine learning pipeline :**\n",
    "\n",
    "     To define our problem, we need to answer these questions:\n",
    "\n",
    "  * What is the main objective? What are we trying to predict?\n",
    "  * What are the target features?\n",
    "  * What is the input data? Is it available?\n",
    "  * What kind of problem are we facing?\n",
    "\n",
    "## *  **Collecting Data** \n",
    "This is the first real step towards the real development of a machine learning model, collecting data. This is a critical step that will cascade in how good the model will be, the more and better data that we get, the better our model will perform.\n",
    "## *  **Preparing the Data**\n",
    "Before beginning to train model, we should transform our data in a way that can be fed into a Machine Learning model. The most common techniques are:\n",
    "\n",
    " * Dealing with missing data\n",
    "  * Feature Scaling\n",
    " *  Splitting Data into Subsets\n",
    "* # **Choosing Model**\n",
    "* ### Supervised learning :\n",
    "Instead of manually writing down exact rules to do the classification, the point in supervised machine learning is to take a number of examples, label each one by the correct label, and use them to ‚Äútrain‚Äù an AI method to automatically recognize the correct label for the training examples.\n",
    "![supervised ](Images/4_1_supervised-learning.093ef920.svg)\n",
    "* ### Unsupervised learning :\n",
    "In unsupervised learning, the correct answers are not provided. This makes the situation quite different since we can't build the model by making it fit the correct answers on training data. It also makes the evaluation of performance more complicated since we can't check whether the learned model is doing well or not.\n",
    "* ### Reinforcement learning: \n",
    "Commonly used in situations where an ML agent like a self-driving car must operate in an environment and where feedback about good or bad choices is available with some delay. Also used in games where the outcome may be decided only at the end of the game.\n",
    "![graphes  ]()\n",
    "\n",
    "![alt image sklearn ](Images/MLhG2.png)\n",
    "\n",
    "* ## **Training** üèãÔ∏è‚Äç‚ôÇÔ∏è\n",
    "We will by the simpliest model you could have.\n",
    "Linear regression is better suited in situations where the output variable can be any number like the price of a product, the distance to an obstacle, the box-office revenue of the next Star Wars movie, and so on.\n",
    "* # Simple Linear Regression\n",
    "Simple Linear Regression is a statistical model, widely used in ML regression tasks, based on the idea that the relationship between two variables can be explained by the following formula:\n",
    "![ y=ax+b ](Images/y=ax+b+e.png)\n",
    "![alt grapheLR ](Images/grapheLR.png)\n",
    "\n",
    "If we have more than one input, variables can be explained by the following formula:  Y=ax1+bx2+cx3+‚ãØ+K+ Œµ\n",
    "\n",
    "![alt matrixForm ](Images/matrix_form.png)\n",
    "\n",
    "\n",
    "![alt estima ](Images/estima.png)\n",
    "![alt estimB ](Images/estimB.png)\n",
    "![alt gradient ](Images/gradientDescent.png)\n",
    "\n",
    "* ## Logistic Regression\n",
    "\n",
    "We can turn the linear regression method‚Äôs outputs into predictions about labels. The technique for doing this is called logistic regression. We take the output from linear regression, which is a number, and predict one label A if the output is greater than zero, and another label B if the output is less than or equal to zero. For example: \n",
    "   * To predict whether an email is spam (1) or (0)\n",
    "   * Whether the tumor is malignant (1) or not (0)\n",
    "   * Handwritten digits, in which case there are ten possible labels.\n",
    "\n",
    "* # Neural Network \n",
    "* ### The human nervous system\n",
    "Human nervous system consists of billions of neurons. These neurons collectively process input received from sensory organs, process the information, and decides what to do in reaction to the input. A typical neuron in the human nervous system has three main parts: dendrites, nucleus, and axons. The information passed to a neuron is received by dendrites. The nucleus is responsible for processing this information. The output of a neuron is passed to other neurons via the axon, which is connected to the dendrites of other neurons further down the network.\n",
    "* ### Perceptron\n",
    "Artificial neural networks are inspired by the human neural network architecture. The simplest neural network consists of only one neuron and is called a perceptron, as shown in the figure below:\n",
    "![alt perceptron ](Images/perceptron.jpg)\n",
    "A perceptron has one input layer and one neuron. Input layer acts as the dendrites and is responsible for receiving the inputs. The number of nodes in the input layer is equal to the number of features in the input dataset. Each input is multiplied with a weight (which is typically initialized with some random value) and the results are added together. The sum is then passed through an activation function. The activation function of a perceptron resembles the nucleus of human nervous system neuron. It processes the information and yields an output. In the case of a perceptron, this output is the final outcome. However, in the case of multilayer perceptrons, the output from the neurons in the previous layer serves as the input to the neurons of the proceeding layer.\n",
    "\n",
    "* ### MultiLayer Perceptron\n",
    "Now that we know what a single layer perceptron is, we can extend this discussion to multilayer perceptrons, or more commonly known as artificial neural networks. A single layer perceptron can solve simple problems where data is linearly separable in to 'n' dimensions, where 'n' is the number of features in the dataset. However, in case of non-linearly separable data, the accuracy of single layer perceptron decreases significantly. Multilayer perceptrons, on the other hand, can work efficiently with non-linearly separable data.\n",
    "* ### In search of non linearity\n",
    "* #### Feature crosses\n",
    "![alt crosses ](https://)\n",
    "However if we use a model that is too complicated, such as one with too many crosses, we give it the opportunity to fit to the noise in the training data, often at the cost of making the model perform badly on test data.\n",
    "#### A neural network executes in two phases: Feed-Forward and Back Propagation.\n",
    "* ## FeedForward\n",
    "Following are the steps performed during the feed-forward phase:\n",
    "\n",
    " 1. The values received in the input layer are multiplied with the weights. A bias is added to the summation of the inputs and weights in order to avoid null values.\n",
    " 2. Each neuron in the first hidden layer receives different values from the input layer depending upon the weights and bias. Neurons have an activation function that operates upon the value received from the input layer. The activation function can be of many types, like a step function, sigmoid function, relu function, or tanh function. As a rule of thumb, relu function is used in the hidden layer neurons and sigmoid function is used for the output layer neuron.\n",
    "  3. The outputs from the first hidden layer neurons are multiplied with the weights of the second hidden layer; the results are summed together and passed to the neurons of the proceeding layers. This process continues until the outer layer is reached. The values calculated at the outer layer are the actual outputs of the algorithm.\n",
    "\n",
    "- The feed-forward phase consists of these three steps. However, the predicted output is not necessarily correct right away; it can be wrong, and we need to correct it. The purpose of a learning algorithm is to make predictions that are as accurate as possible. To improve these predicted results, a neural network will then go through a back propagation phase. During back propagation, the weights of different neurons are updated in a way that the difference between the desired and predicted output is as small as possible.\n",
    "\n",
    "* ## BackPropagation\n",
    "Back propagation phase consists of the following steps:\n",
    "\n",
    " 1. The error is calculated by quantifying the difference between the predicted output and the desired output. This difference is called \"loss\" and the function used to calculate the difference is called the \"loss function\". Loss functions can be of different types e.g. mean squared error or cross entropy functions. Remember, neural networks are supervised learning algorithms that need the desired outputs for a given set of inputs, which is what allows it to learn from the data.\n",
    " 2. Once the error is calculated, the next step is to minimize that error. To do so, partial derivative of the error function is calculated with respect to all the weights and biases. This is called gradient decent. The derivatives can be used to find the slope of the error function. If the slop is positive, the value of the weights can be reduced or if the slop is negative the value of weight can be increased. This reduces the overall error. The function that is used to reduce this error is called the optimization function.\n",
    "\n",
    "- This one cycle of feed-forward and back propagation is called one \"epoch\". This process continues until a reasonable accuracy is achieved. There is no standard for reasonable accuracy, ideally you'd strive for 100% accuracy, but this is extremely difficult to achieve for any non-trivial dataset. In many cases 90%+ accuracy is considered acceptable, but it really depends on your use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width       Target\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Location of dataset\n",
    "url = \"Datasets/Iris.data\"\n",
    "\n",
    "# Assign colum names to the dataset\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Target']\n",
    "\n",
    "# Read dataset to pandas dataframe\n",
    "irisdata = pd.read_csv(url, names=names) \n",
    "print(type(irisdata))\n",
    "irisdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris data set dimensions : (150, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Iris data set dimensions : {}\".format(irisdata.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal-length    150 non-null float64\n",
      "sepal-width     150 non-null float64\n",
      "petal-length    150 non-null float64\n",
      "petal-width     150 non-null float64\n",
      "Target          150 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "irisdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal-length    0\n",
       "sepal-width     0\n",
       "petal-length    0\n",
       "petal-width     0\n",
       "Target          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisdata.isnull().sum()\n",
    "irisdata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target\n",
       "0  Iris-setosa\n",
       "1  Iris-setosa\n",
       "2  Iris-setosa\n",
       "3  Iris-setosa\n",
       "4  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign data from first four columns to X variable\n",
    "X = irisdata.iloc[:, 0:4]\n",
    "\n",
    "# Assign data from first fifth columns to y variable\n",
    "y = irisdata.select_dtypes(include=[object])  \n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "a = y.Target.unique()  \n",
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing  \n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "y = y.apply(le.fit_transform) \n",
    "y.Target.unique()\n",
    "irisdata=irisdata.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(irisdata.astype(float).corr(),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Target\n",
      "147       2\n",
      "139       2\n",
      "108       2\n",
      "128       2\n",
      "36        0\n",
      "30        0\n",
      "15        0\n",
      "134       2\n",
      "3         0\n",
      "105       2\n",
      "141       2\n",
      "89        1\n",
      "146       2\n",
      "135       2\n",
      "138       2\n",
      "31        0\n",
      "97        1\n",
      "1         0\n",
      "103       2\n",
      "37        0\n",
      "81        1\n",
      "51        1\n",
      "7         0\n",
      "107       2\n",
      "95        1\n",
      "33        0\n",
      "40        0\n",
      "28        0\n",
      "111       2\n",
      "64        1\n",
      "..      ...\n",
      "96        1\n",
      "113       2\n",
      "123       2\n",
      "43        0\n",
      "70        1\n",
      "94        1\n",
      "38        0\n",
      "115       2\n",
      "2         0\n",
      "42        0\n",
      "48        0\n",
      "77        1\n",
      "137       2\n",
      "143       2\n",
      "22        0\n",
      "20        0\n",
      "26        0\n",
      "54        1\n",
      "19        0\n",
      "122       2\n",
      "56        1\n",
      "47        0\n",
      "45        0\n",
      "74        1\n",
      "27        0\n",
      "114       2\n",
      "10        0\n",
      "102       2\n",
      "53        1\n",
      "14        0\n",
      "\n",
      "[120 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier  \n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)  \n",
    "mlp.fit(X_train, y_train.values.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  1  9]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         9\n",
      "          1       0.92      1.00      0.96        11\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 0 0]\n",
      " [1 4 6]\n",
      " [0 1 9]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95         9\n",
      "          1       0.80      0.36      0.50        11\n",
      "          2       0.60      0.90      0.72        10\n",
      "\n",
      "avg / total       0.76      0.73      0.71        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Users\\Redha\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier  \n",
    "mlp = MLPClassifier(hidden_layer_sizes=(1), max_iter=1000)  \n",
    "mlp.fit(X_train , y_train.values.ravel()) \n",
    "predictions = mlp.predict(X_test)  \n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
